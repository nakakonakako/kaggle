{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "VER = 1\n",
    "\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "test = pd.read_csv(\"dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "  df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1}).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"Sex\", \"Age\", \"Height\", \"Weight\", \"Duration\", \"Heart_Rate\", \"Body_Temp\"]\n",
    "TARGET = \"Calories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version 2.17.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print(\"TF Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(size=len(FEATURES)):\n",
    "  x_in = Input(shape=(size, ))\n",
    "  x = Dense(32)(x_in)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"swish\")(x)\n",
    "  \n",
    "  x = Dense(64)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(\"swish\")(x)\n",
    "  \n",
    "  x = Dense(1, activation=\"linear\")(x)\n",
    "  model = Model(inputs=x_in, outputs=x)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def make_callbacks():\n",
    "  lr_callback = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verboe=1,\n",
    "    min_lr=1e-6\n",
    "  )\n",
    "  early_stop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    "  )\n",
    "  return [lr_callback, early_stop_cb]\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "########## Fold 1 ##########\n",
      "############################\n",
      "Normalizingâ€¦done\n",
      "Epoch 1/100\n",
      "2344/2344 - 6s - 2ms/step - loss: 0.7590 - root_mean_squared_error: 0.8712 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0102 - root_mean_squared_error: 0.1008 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0102 - root_mean_squared_error: 0.1012 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0096 - root_mean_squared_error: 0.0979 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0089 - root_mean_squared_error: 0.0946 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0079 - root_mean_squared_error: 0.0889 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0079 - root_mean_squared_error: 0.0888 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0073 - root_mean_squared_error: 0.0855 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645 - learning_rate: 2.5000e-04\n",
      "Epoch 14/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0072 - root_mean_squared_error: 0.0850 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631 - learning_rate: 2.5000e-04\n",
      "Epoch 15/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0071 - root_mean_squared_error: 0.0842 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0071 - root_mean_squared_error: 0.0842 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0068 - root_mean_squared_error: 0.0824 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635 - learning_rate: 1.2500e-04\n",
      "Epoch 19/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0068 - root_mean_squared_error: 0.0824 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629 - learning_rate: 1.2500e-04\n",
      "Epoch 20/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0067 - root_mean_squared_error: 0.0820 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664 - learning_rate: 1.2500e-04\n",
      "Epoch 21/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632 - learning_rate: 6.2500e-05\n",
      "Epoch 22/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0066 - root_mean_squared_error: 0.0815 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630 - learning_rate: 6.2500e-05\n",
      "Epoch 23/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0066 - root_mean_squared_error: 0.0811 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646 - learning_rate: 6.2500e-05\n",
      "Epoch 24/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 3.1250e-05\n",
      "Epoch 25/100\n",
      "2344/2344 - 5s - 2ms/step - loss: 0.0065 - root_mean_squared_error: 0.0807 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 3.1250e-05\n",
      "Epoch 26/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0802 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623 - learning_rate: 3.1250e-05\n",
      "Epoch 27/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 1.5625e-05\n",
      "Epoch 28/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 1.5625e-05\n",
      "Epoch 29/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 1.5625e-05\n",
      "Epoch 30/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 7.8125e-06\n",
      "Epoch 31/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623 - learning_rate: 7.8125e-06\n",
      "Epoch 32/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0065 - root_mean_squared_error: 0.0803 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623 - learning_rate: 7.8125e-06\n",
      "Epoch 33/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 7.8125e-06\n",
      "Epoch 34/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 3.9063e-06\n",
      "Epoch 35/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623 - learning_rate: 3.9063e-06\n",
      "Epoch 36/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0062 - root_mean_squared_error: 0.0788 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623 - learning_rate: 3.9063e-06\n",
      "Epoch 37/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.9531e-06\n",
      "Epoch 38/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0800 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.9531e-06\n",
      "Epoch 39/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626 - learning_rate: 1.9531e-06\n",
      "Epoch 40/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0793 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.0000e-06\n",
      "Epoch 41/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0799 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624 - learning_rate: 1.0000e-06\n",
      "Epoch 42/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.0000e-06\n",
      "Epoch 43/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630 - learning_rate: 1.0000e-06\n",
      "Epoch 44/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623 - learning_rate: 1.0000e-06\n",
      "Epoch 45/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625 - learning_rate: 1.0000e-06\n",
      "Epoch 46/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.0000e-06\n",
      "Epoch 47/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625 - learning_rate: 1.0000e-06\n",
      "Epoch 48/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.0000e-06\n",
      "Epoch 49/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.0000e-06\n",
      "Epoch 50/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622 - learning_rate: 1.0000e-06\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "293/293 - 1s - 2ms/step\n",
      "489/489 - 0s - 881us/step\n",
      "Fold 1 RMSE: 0.0622\n",
      "Feature engineering & training time: 193.6 sec\n",
      "\n",
      "############################\n",
      "########## Fold 2 ##########\n",
      "############################\n",
      "Normalizingâ€¦done\n",
      "Epoch 1/100\n",
      "2344/2344 - 5s - 2ms/step - loss: 0.4451 - root_mean_squared_error: 0.6671 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0139 - root_mean_squared_error: 0.1177 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0109 - root_mean_squared_error: 0.1042 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0101 - root_mean_squared_error: 0.1007 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "2344/2344 - 4s - 2ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "FOLDS = 5\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "pred = np.zeros(len(test))\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(train)):\n",
    "  print(f\"\\n{'#'*28}\")\n",
    "  print(f\"{'#'*10} Fold {i+1} {'#'*10}\")\n",
    "  print(f\"{'#'*28}\")\n",
    "  \n",
    "  X_train = train.loc[train_idx, FEATURES].copy()\n",
    "  y_train = np.log1p(train.loc[train_idx, TARGET])\n",
    "  \n",
    "  X_valid = train.loc[valid_idx, FEATURES].copy()\n",
    "  y_valid = np.log1p(train.loc[valid_idx, TARGET])\n",
    "  \n",
    "  X_test = test[FEATURES].copy()\n",
    "  \n",
    "  print(\"Normalizingâ€¦\", end=\"\")\n",
    "  norm_cols = [c for c in FEATURES if c not in []]\n",
    "  means = X_train[norm_cols].mean()\n",
    "  stds = X_train[norm_cols].std()\n",
    "  stds = stds.replace(0, 1)\n",
    "  X_train[norm_cols] = (X_train[norm_cols] - means) / stds\n",
    "  X_valid[norm_cols] = (X_valid[norm_cols] - means) / stds\n",
    "  X_test[norm_cols] = (X_test[norm_cols] - means) / stds\n",
    "  print(\"done\")\n",
    "  \n",
    "  start = time.time()\n",
    "  \n",
    "  K.clear_session()\n",
    "  model = build_model(X_train.shape[1])\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                loss=\"mse\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "              )\n",
    "  model.fit(X_train, y_train,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            callbacks=make_callbacks(),\n",
    "            batch_size=256, epochs=EPOCHS, verbose=2)\n",
    "  \n",
    "  oof[valid_idx] = model.predict(X_valid, batch_size=512, verbose=2).flatten()\n",
    "  pred += model.predict(X_test, batch_size=512, verbose=2).flatten()\n",
    "  \n",
    "  rmse = np.sqrt(mean_squared_error(y_valid, oof[valid_idx]))\n",
    "  print(f\"Fold {i+1} RMSE: {rmse:.4f}\")\n",
    "  print(f\"Feature engineering & training time: {time.time() - start:.1f} sec\")\n",
    "\n",
    "pred /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rmse = np.sqrt(mean_squared_error(np.log1p(train[TARGET]), oof))\n",
    "print(f\"Overall CV RMSE: {full_rmse:.5f}\")\n",
    "np.save(f\"oof_v{VER}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = train.Calories.min()\n",
    "mx = train.Calories.max()\n",
    "test[\"Calories\"] = np.clip(np.expm1(pred), mn, mx)\n",
    "test[[\"id\", \"Calories\"]].to_csv(f\"dataset/submission_v{VER}.csv\", index=False)\n",
    "test[[\"id\", \"Calories\"]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
